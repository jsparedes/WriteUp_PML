{
    "contents" : "---\ntitle: \"Project Writeup\"\nauthor: \"Jorge Salvador Paredes Merino\"\ndate: \"Thursday, October 25, 2014\"\noutput:\n  html_document:\n    toc: yes\n---\n\n## 1. Dataset\n\nSource: [Human Activity Recognition (PUC-RIO)](http://groupware.les.inf.puc-rio.br/har)\n\n[Training](http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)\n\n[Testing](http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv) (evaluated by )\n\n## 2. Objectives\nPredict the manner in which a group of enthusiasts who take measurements about themselves did the exercise. This is the \"classe\" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. \n\n## 3. Data Processing\n### 3.1. Loading or installing the required packages\nIn this report are used r packages:\n\n- **mi** (to plot missing values with respect of dataset)\n- **caret** (to build machine learning model)\n\nWith the following code, packages required will be loaded or installed in case you do not have them:\n\n```{r}\npackages = c(\"mi\",\"caret\")  # Here, add your required packages\nipak <- function(pkg){                                          \n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])] \n  if (length(new.pkg))                                          \n    install.packages(new.pkg, dependencies = TRUE)              \n  sapply(pkg, require, character.only = TRUE)                   \n}\n\nipak(packages)\n```\n\n### 3.2. Reading datasets\n\n```{r}\nfile_training = \"pml-training.csv\"\nfile_testing = \"pml-testing.csv\"\n\ntraining = read.csv(file_training, sep=\",\", header = TRUE, na.strings= c(\"NA\",\"\",\" \"), nrow=19622)\ntesting = read.csv(file_testing, sep=\",\", header = TRUE, na.strings= c(\"NA\",\"\",\" \"), nrow=20)\n\ndim(training)\ndim(testing)\n```\n\n### 3.2. Cleaning datasets\n\nIn the first instance, are removed attributes related to: timestam, X, usern_name, new_window:\n\n```{r}\nremoveIndex = grep(\"timestamp|X|user_name|new_window\",names(training));\ntraining = training[,-removeIndex];\ntesting = testing[,-removeIndex];\n```\n\nTo have a general overview about the dataset, we can take a look of missing values which are represented in red color, The folling picture (which is rotated) is a part of the dataset. Summary of the dataset is need complement the picture.\n\n```{r}\nmissing.pattern.plot(training[1:200,2:80], ylab = \"\")\nsummary(training)\n```\n\nWe can see many missing values with a curious pattern. Attributes which have missing values present exactly 19216 each one. If we remove registers with missing values we will suffer huge losses in information decreasing from **19622** to **406** registres. \n\nFor this reason, we only delete the column attribute \nwhich present `NA` (missing values).\n\n```{r}\na = colSums(is.na(training))\nc = a!= 19216 # index of attributes to be remained\nfilter_training = training[, c]\nfilter_testing = testing[, c]\n\nsummary(filter_training) # \n\n# Our final predictors, with them we have to build our model:\nnames(filter_training)\nnames(filter_testing)\n```\nDoing this, we got a new dataset: \n\n**New Training** => [19216x53].\n**New Testing** => [20x52], **problem_id** is not considered. It is used by Coursera to evaluated the prediction made by the model.\n\nAt the beginning we have **159** attributes and now we have **52** to build the machine learning model. We can not use the testing set to eval our model, For this reason, it is necessary to split the training dataset into train and validation.\n\n### 3.3. Building Train and Validation datasets\n\n```{r}\ntrainIndex = createDataPartition(training$classe, p = .6,\n                                  list = FALSE,\n                                  times = 1)\ntrain = training[trainIndex, ]\nvalidation = training[-trainIndex, ]\n```\n\n### 3.4. Building Machine Learning Model\n\nIn this part, we will build a **Random Forest** model:\n\n```{r}\nset.seed(625)\n\ntrControl = trainControl(method = \"cv\", number = 10, allowParallel =TRUE)\n\nmodelo_RF = train(classe ~.,data = train, method=\"rf\", trControl=trControl)\n```",
    "created" : 1414162433527.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4092057758",
    "id" : "6EB89101",
    "lastKnownWriteTime" : 1414273727,
    "path" : "E:/Jorge/moocs/Practical ML/WriteUp/PWriteUp.Rmd",
    "project_path" : "PWriteUp.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}