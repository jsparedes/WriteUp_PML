url_training = "pml-training.csv"
training = read.csv(url_training, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=19622)
url_testing = "pml-testing.csv"
testing = read.csv(url_testing, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=20)
removeIndex = grep("timestamp|X|user_name|new_window",names(training));
training = training[,-removeIndex];
testing = testing[,-removeIndex];
summary(training)
missing.pattern.plot(training[1:100,5:30])
library(mi)
missing.pattern.plot(training[1:100,5:30])
missing.pattern.plot(training[1:100,5:50])
missing.pattern.plot(training[1:100,5:70])
missing.pattern.plot(training[1:100,5:70], avoid="dodge") + scale_y_sqrt()
ggmissing(mmissing, avoid="dodge")
ggmissing(mmissing, avoid="dodge")
library(mi)
ggmissing(mmissing, avoid="dodge")
missing.pattern.plot(training[1:100,5:70], y.order = FALSE, x.order = FALSE
)
missing.pattern.plot(training[1:100,5:70], y.order = FALSE, x.order = FALSE,
xlab = "Index", ylab = "Variable" )
missing.pattern.plot(training[1:200,5:70])
missing.pattern.plot(training[1:2000,5:70])
missing.pattern.plot(training[1:200,])
missing.pattern.plot(training[1:200,2:8])
missing.pattern.plot(training[1:200,2:80])
missing.pattern.plot(training[1:200,2:80], ylab = "")
missing.pattern.plot(training[1:200,2:80], ylab = " ")
missing.pattern.plot(training[180:500,2:80], ylab = " ")
missing.pattern.plot(training[1:200,2:80], ylab = "")
a = colSums(is.na(training))
a
a!=19216
b = a!= 19216
training = training[, b]
testing = testing[, c]
c = a!= 19216
training = training[, c]
testing = testing[, c]
names(training)
sum(c)
nrow(training)-sum(c)
summary(training)
trControl = trainControl(method = "cv", number = 4, allowParallel =TRUE)
modFitRF = train(trainData$classe ~.,data = training,method="rf")
library(caret)
trControl = trainControl(method = "cv", number = 4, allowParallel =TRUE)
modFitRF = train(trainData$classe ~.,data = training,method="rf",trControl=trControl)
modFitRF = train(classe ~.,data = training,method="rf",trControl=trControl)
install.packages("doParallel")
library(foreach)
library(doParallel)
registerDoParallel()
url_training = "pml-training.csv"
training = read.csv(url_training, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=19622)
url_testing = "pml-testing.csv"
testing = read.csv(url_testing, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=20)
# In the first instance, are removed attributes related to: timestam, X, usern_name, new_window
removeIndex = grep("timestamp|X|user_name|new_window",names(training));
training = training[,-removeIndex];
testing = testing[,-removeIndex];
summary(training)
# function de mi package
missing.pattern.plot(training[1:200,2:80], ylab = "")
# We can see many missing values with a curious pattern:
# attributes which have missing values present exactly 19216 each one
# If we remove registers with missing values we will suffer an enormous decreasing
# from 19622 to 406. For this reason, we only delete the column attribute
# which present NA (missing values).
# Doing this, we got a new dataset: [19216x53]
# Namely, nrow(training)-sum(c) attributes left out
a = colSums(is.na(training))
c = a!= 19216 # index of columnas with 19216 missing values each one
training = training[, c]
testing = testing[, c]
# Esta cantidad de columnas quedan fuera de analisis:
summary(training) # Ya no observamos missing values
# Atributos a explorar:
names(training)
model = foreach(ntree=rep(150, 4), .combine=randomForest::combine) %dopar% randomForest(training[-ncol(training)], training$classe, ntree=ntree)
library(randomForest)
model = foreach(ntree=rep(150, 4), .combine=randomForest::combine) %dopar% randomForest(training[-ncol(training)], training$classe, ntree=ntree)
install.packages("C:/Users/jparedes/Downloads/doMC_1.3.3.tar.gz", repos = NULL, type = "source")
trControl = trainControl(method = "cv", number = 2, allowParallel =TRUE)
modFitRF = train(classe ~.,data = training,method="rf",trControl=trControl)
library(Caret)
trControl = trainControl(method = "cv", number = 2, allowParallel =TRUE)
modFitRF = train(classe ~.,data = training,method="rf",trControl=trControl)
library(caret)
trControl = trainControl(method = "cv", number = 2, allowParallel =TRUE)
modFitRF = train(classe ~.,data = training,method="rf",trControl=trControl)
modFitRF = train(classe ~.,data = training,method="rf",trControl=trControl)
0.
predictedValues = predict(modFitRF,testing);
View(predictedValues);
pRes = postResample(predictedValues, testing$classe)
cfM = confusionMatrix(predictedValues, testing$classe)
cfM = confusionMatrix(predictedValues, testing$classe)
View(testing)
testing$classe
View(training)
url_testing = "pml-testing.csv"
testing = read.csv(url_testing, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=20)
View(testing)
testing = testing[, c]
View(testing)
url_testing = "pml-testing.csv"
testing = read.csv(url_testing, sep=",", header = TRUE, na.strings= c("NA",""," "), nrow=20)
# In the first instance, are removed attributes related to: timestam, X, usern_name, new_window
removeIndex = grep("timestamp|X|user_name|new_window",names(training));
testing = testing[,-removeIndex];
testing = testing[, c]
predictedValues
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictedValues)
install.packages("googleVis")
modFitRF
trainIndex = createDataPartition(iris$Species, p = .8,
list = FALSE,
times = 1)
train = training[trainIndex, ]
validation = training[-trainIndex, ]
trainIndex = createDataPartition(training$classe, p = .8,
list = FALSE,
times = 1)
train = training[trainIndex, ]
validation = training[-trainIndex, ]
trainIndex = createDataPartition(training$classe, p = .7,
list = FALSE,
times = 1)
train = training[trainIndex, ]
validation = training[-trainIndex, ]
str(train)
summary(training)
